# 🌟 **MyTransformers 项目** 🌟

**项目概述**  
该项目的目标是利用个人数据（如日记和微信聊天记录）训练一个自定义的 GPT 模型 🤖📓。模型采用纯解码器的 Transformer 架构 📐，旨在探索使用私人数据预训练语言模型的效果 🌍，尽管此举在学术或商业上没有明显的价值，但对于个人成长具有极大的意义 💪✨。

---

## 🏗 **架构设计** 🏗
1. **上下文长度**：128 📝  
2. **模型类型**：Decoder Only 🛠️

---

## 📊 **数据** 📊
1. **预训练数据**：个人日记 🗒️  
2. **SFT（监督微调）数据**：微信聊天记录 💬

---

## 📅 **日志** 📅
这是一个记录打卡贴，作者计划优化一个映射函数 \( f: X \mapsto Y \) 🔄，逐步优化模型，分享过程和心得 💡。

项目仓库链接：  
🔗 [MyTransformers 项目仓库](https://github.com/NytePlus/MyTransformers)

---

## 🧐 **项目价值** 🧐
⚠️ **免责声明**：本项目没有学术或商业价值，主要是个人成长的探索 🚶‍♂️📈。  
本项目的重点是使用个人数据进行模型预训练，尽管现有的 Lora 微调或 prompt 现有大模型的方式更为高效 ⚙️，但使用独特的私人数据训练模型的好奇心驱动了这个项目 🧠🔍。如果这个探索能引起其他感兴趣的读者共鸣，那它就具备了意义 🎯💥。

---

## 📚 **关于深度学习的启发** 📚
作者来自工科背景，在大一上 C++ 课时 🖥️，因讨论快速排序的参考值选择问题，被老师建议去学习《机器学习》 📖。从那时起，作者接触了周志华的《机器学习》 📕，这成为了他深度学习探索的起点 🧠，并激发了他对这门学科的极大兴趣 💡。

---

## ✍️ **关于日记的点滴** ✍️
作者自小学四年级开始坚持写日记 📓，这一习惯一直持续至今 🕰️。通过回顾这些日记，作者意识到自己情绪和思想的变化 😌➡️🤔，日记从单纯的叙事逐渐转变为更深的反思和论证 ✍️📖。日记不仅是情感的记录 💬，也成为了思维的镜子 🔍。

---

## 🔥 **分享方向** 🔥
未来，作者计划从以下几个方面进行分享 📤：
- **原料（数据）** 🗃️：展示用于模型训练的日记和聊天记录 📂
- **丹方（架构设计）** 🛠️：深入解析神经网络的架构设计 🧩
- **代码与讲解** 💻：分享代码实现与详细解释 💡
- **训练过程** 🏋️：展示训练进展，并提供阶段性的在线 demo 供读者测试 🎮

---


💡 **项目的意义在于探索与坚持** 💡  
尽管重新做模型预训练在技术上可能不如微调现有模型高效 📉，但这段旅程更多的是对个人成长和技术好奇心的挑战 🧗‍♂️。希望能够在此过程中收获知识 🧠📈，也希望能与其他爱好者共鸣！💬

🤝 **如果你也对使用个人数据训练模型感兴趣，欢迎交流！** 🤗
