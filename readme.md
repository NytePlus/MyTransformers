## 架构设计
1.上下文长度 128

2.Decoder Only
## 数据
1.pretrain: 日记

2.SFT: wechat聊天记录

## 日志
这是一个记录打卡贴，lz计划优化一个映射 $ f: X \mapsto Y $ 
#### 项目仓库 https://github.com/NytePlus/MyTransformers
## 这个项目有什么价值
事先声明，这没有什么学术或商业价值，仅有个人成长的价值。因此，我实在想不到别的地方能够分享我的成果，发不了论文的话就发发水源吧 :drooling_face:。当下重新做模型的预训练没有什么用，使用lora进行微调、或者prompt一些已有大模型可能能达到更好的效果。但我想使用独属于自己的数据训练，我很好奇最终会达到什么效果。如果能遇到感兴趣的读者，那就很有价值了！ :smiling_face_with_three_hearts:
## 关于深度学习
lz来自工科大平台，大一上的时候在C++课上和老师讨论快速排序的参考值选择的问题。讨论的结果是老师告诉我，你学这些算法没用，这些都是上个世纪的东西了，建议你看看《机器学习》。于是lz看了看周志华的《机器学习》，忽然觉得这正是我想找的东西。
## 关于日记
小学四年级的时候，我开始每天记日记。那时候好像每天都很开心，有各种各样有趣的事，于是日记里全是叙事。后来我还是一直记日记，初中、高中、大学，我能分明地感觉到自己的变化，仿佛再也没有真正的开心过了，日记的风格从叙事变成大片大片的论证。
## 计划从以下几个方向分享
* 原料（数据）
* 丹方（神经网络架构设计）
* 代码 + 讲解
* 训练过程 + 阶段性online demo

[这是一个记录打卡贴，lz计划训练一个自己的小型gpt。具体来说用pytorch搭建一个纯解码器Transformer，使用自己的日记做预训练，微信聊天记录作为多轮对话数据，训练自己的gpt。
#### 项目仓库 https://github.com/NytePlus/MyTransformers
## 这个项目有什么价值
事先声明，这没有什么学术或商业价值，仅有个人成长的价值。因此，我实在想不到别的地方能够分享我的成果，发不了论文的话就发发水源吧 :drooling_face:。当下重新做模型的预训练没有什么用，使用lora进行微调、或者prompt一些已有大模型可能能达到更好的效果。但我想使用独属于自己的数据训练，我很好奇最终会达到什么效果。如果能遇到感兴趣的读者，那就很有价值了！ :smiling_face_with_three_hearts:
## 关于深度学习
lz来自工科大平台，大一上的时候在C++课上和老师讨论快速排序的参考值选择的问题。讨论的结果是老师告诉我，你学这些算法没用，这些都是上个世纪的东西了，建议你看看《机器学习》。于是lz看了看周志华的《机器学习》，忽然觉得这正是我想找的东西。
## 关于日记
小学四年级的时候，我开始每天记日记。那时候好像每天都很开心，有各种各样有趣的事，于是日记里全是叙事。后来我还是一直记日记，初中、高中、大学，我能分明地感觉到自己的变化，仿佛再也没有真正的开心过了，日记的风格从叙事变成大片大片的论证。
## 计划从以下几个方向分享
* 原料（数据）
* 丹方（神经网络架构设计）
* 代码 + 讲解
* 训练过程 + 阶段性online demo]()